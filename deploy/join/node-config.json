[
  {
    "id": "node1",
    "host": "inference",
    "inference_port": 5000,
    "poc_port": 8080,
    "max_concurrent": 500,
    "models": {
      "Qwen/Qwen3-32B-FP8": {
        "args": [
          "--quantization",
          "fp8",
          "--gpu-memory-utilization",
          "0.9"
        ]
      }
    },
    "hardware": [
      {
        "type": "CPU",
        "count": 20
      }
    ]
  }
]
